name: Test Pull Requests

on:
  pull_request:
    branches: [ main, develop ]
    types: [opened, synchronize, reopened]

env:
  PYTHON_VERSION: '3.10'

jobs:
  # Job 1: Code Quality Checks
  code-quality:
    name: ğŸ” Code Quality
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch full history for better analysis

    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: ğŸ“¦ Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt', '**/test_requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: ğŸ”§ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r test_requirements.txt
        pip install flake8 black isort bandit safety

    - name: ğŸ¨ Check code formatting with Black
      run: |
        echo "ğŸ¨ Checking code formatting..."
        black --check --diff .
      continue-on-error: true

    - name: ğŸ“ Check import sorting with isort
      run: |
        echo "ğŸ“ Checking import sorting..."
        isort --check-only --diff .
      continue-on-error: true

    - name: ğŸ§¹ Lint with flake8
      run: |
        echo "ğŸ§¹ Linting code..."
        # Stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # Treat all other errors as warnings
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=120 --statistics

    - name: ğŸ”’ Security scan with bandit
      run: |
        echo "ğŸ”’ Running security scan..."
        bandit -r . -f json -o bandit-report.json || true
        bandit -r . -ll || true
      continue-on-error: true

    - name: ğŸ›¡ï¸ Check dependencies with safety
      run: |
        echo "ğŸ›¡ï¸ Checking dependencies for known vulnerabilities..."
        safety check --json --output safety-report.json || true
        safety check || true
      continue-on-error: true

  # Job 2: Unit Tests
  unit-tests:
    name: ğŸ§ª Unit Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.10', '3.11']
    
    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4

    - name: ğŸ Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: ğŸ“¦ Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-${{ matrix.python-version }}-pip-${{ hashFiles('**/requirements.txt', '**/test_requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.python-version }}-pip-

    - name: ğŸ”§ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r test_requirements.txt

    - name: ğŸ§ª Run unit tests
      run: |
        python -m pytest tests/ -v \
          --tb=short \
          --cov=core \
          --cov=app \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term \
          --junitxml=pytest-results.xml
      env:
        DISABLE_FIREBASE: true
        AWS_ACCESS_KEY_ID: test
        AWS_SECRET_ACCESS_KEY: test
        S3_BUCKET_NAME: test-bucket

    - name: ğŸ“Š Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}
        path: |
          pytest-results.xml
          htmlcov/
          coverage.xml

    - name: ğŸ“ˆ Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-${{ matrix.python-version }}
        fail_ci_if_error: false

  # Job 3: Lambda Handler Tests
  lambda-tests:
    name: âš¡ Lambda Handler Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4

    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: ğŸ”§ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: ğŸ§ª Test Lambda handler import
      run: |
        python -c "
        import sys
        sys.path.append('.')
        try:
            from lambda_handler import lambda_handler
            print('âœ… Lambda handler imported successfully')
        except ImportError as e:
            print(f'âŒ Failed to import lambda handler: {e}')
            sys.exit(1)
        "

    - name: ğŸ§ª Test Lambda handler execution
      run: |
        python -c "
        import sys
        import json
        sys.path.append('.')
        from lambda_handler import lambda_handler
        
        # Test different event formats
        test_cases = [
            {
                'name': 'API Gateway v1',
                'event': {
                    'httpMethod': 'GET',
                    'path': '/health',
                    'headers': {},
                    'queryStringParameters': None,
                    'body': None,
                    'isBase64Encoded': False
                }
            },
            {
                'name': 'API Gateway v2',
                'event': {
                    'version': '2.0',
                    'requestContext': {'http': {'method': 'GET'}},
                    'rawPath': '/health',
                    'headers': {},
                    'queryStringParameters': None,
                    'body': None,
                    'isBase64Encoded': False
                }
            },
            {
                'name': 'CORS Preflight',
                'event': {
                    'httpMethod': 'OPTIONS',
                    'path': '/upload',
                    'headers': {},
                    'queryStringParameters': None,
                    'body': None,
                    'isBase64Encoded': False
                }
            }
        ]
        
        class MockContext:
            function_name = 'test-function'
            aws_request_id = 'test-request-id'
        
        context = MockContext()
        
        for test_case in test_cases:
            try:
                result = lambda_handler(test_case['event'], context)
                print(f'âœ… {test_case[\"name\"]}: Status {result[\"statusCode\"]}')
                
                # Verify response structure
                assert 'statusCode' in result
                assert 'headers' in result
                assert 'body' in result
                assert isinstance(result['statusCode'], int)
                
                # Verify CORS headers
                assert 'Access-Control-Allow-Origin' in result['headers']
                
            except Exception as e:
                print(f'âŒ {test_case[\"name\"]} failed: {e}')
                sys.exit(1)
        
        print('âœ… All Lambda handler tests passed')
        "
      env:
        DISABLE_FIREBASE: true

  # Job 4: Build Test
  build-test:
    name: ğŸ—ï¸ Build Test
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4

    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: ğŸ“¦ Test deployment package creation
      run: |
        echo "ğŸ—ï¸ Testing deployment package creation..."
        
        # Create package directory
        mkdir -p package
        
        # Install dependencies
        pip install -r requirements.txt -t package/
        
        # Copy application code
        cp -r core package/
        cp app.py package/
        cp lambda_handler.py package/
        
        # Remove unnecessary files
        find package/ -type d -name "__pycache__" -exec rm -rf {} + || true
        find package/ -type d -name "*.egg-info" -exec rm -rf {} + || true
        find package/ -type f -name "*.pyc" -delete || true
        find package/ -type f -name "*.pyo" -delete || true
        find package/ -name "tests" -type d -exec rm -rf {} + || true
        
        # Create zip file
        cd package
        zip -r ../test-package.zip . -x "*.git*" "*.DS_Store*" "*__pycache__*"
        cd ..
        
        # Check package size
        PACKAGE_SIZE=$(stat -f%z test-package.zip 2>/dev/null || stat -c%s test-package.zip)
        echo "ğŸ“¦ Package size: $(($PACKAGE_SIZE / 1024 / 1024)) MB"
        
        # Verify package contents
        echo "ğŸ“‹ Package contents:"
        unzip -l test-package.zip | head -20
        
        # Test that the package can be imported
        cd package
        python -c "
        import sys
        sys.path.insert(0, '.')
        try:
            import app
            import lambda_handler
            import core.auth_middleware
            import core.firestore_db
            import core.s3_storage
            print('âœ… All modules can be imported from package')
        except ImportError as e:
            print(f'âŒ Import error in package: {e}')
            sys.exit(1)
        "

    - name: ğŸ“¤ Upload test package
      uses: actions/upload-artifact@v3
      with:
        name: test-deployment-package
        path: test-package.zip
        retention-days: 1

  # Job 5: Documentation Check
  docs-check:
    name: ğŸ“š Documentation Check
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4

    - name: ğŸ“š Check README and documentation
      run: |
        echo "ğŸ“š Checking documentation..."
        
        # Check if README exists and has content
        if [ -f "README.md" ]; then
          README_SIZE=$(wc -l < README.md)
          if [ $README_SIZE -gt 10 ]; then
            echo "âœ… README.md exists and has content ($README_SIZE lines)"
          else
            echo "âš ï¸ README.md is too short"
          fi
        else
          echo "âŒ README.md is missing"
          exit 1
        fi
        
        # Check if ARCHITECTURE.md exists
        if [ -f "ARCHITECTURE.md" ]; then
          echo "âœ… ARCHITECTURE.md exists"
        else
          echo "âš ï¸ ARCHITECTURE.md is missing"
        fi
        
        # Check for requirements.txt
        if [ -f "requirements.txt" ]; then
          echo "âœ… requirements.txt exists"
          echo "ğŸ“¦ Dependencies:"
          cat requirements.txt
        else
          echo "âŒ requirements.txt is missing"
          exit 1
        fi

    - name: ğŸ” Check for TODO comments
      run: |
        echo "ğŸ” Checking for TODO comments..."
        TODO_COUNT=$(grep -r "TODO\|FIXME\|XXX" --include="*.py" . | wc -l || echo "0")
        echo "ğŸ“ Found $TODO_COUNT TODO/FIXME comments"
        
        if [ $TODO_COUNT -gt 0 ]; then
          echo "ğŸ“‹ TODO items found:"
          grep -r "TODO\|FIXME\|XXX" --include="*.py" . || true
        fi

  # Job 6: Summary
  pr-summary:
    name: ğŸ“‹ PR Summary
    runs-on: ubuntu-latest
    needs: [code-quality, unit-tests, lambda-tests, build-test, docs-check]
    if: always()
    
    steps:
    - name: ğŸ“‹ Generate PR summary
      run: |
        echo "ğŸ“‹ Pull Request Test Summary"
        echo "=========================="
        echo ""
        
        # Check job results
        if [ "${{ needs.code-quality.result }}" = "success" ]; then
          echo "âœ… Code Quality: PASSED"
        else
          echo "âŒ Code Quality: FAILED"
        fi
        
        if [ "${{ needs.unit-tests.result }}" = "success" ]; then
          echo "âœ… Unit Tests: PASSED"
        else
          echo "âŒ Unit Tests: FAILED"
        fi
        
        if [ "${{ needs.lambda-tests.result }}" = "success" ]; then
          echo "âœ… Lambda Tests: PASSED"
        else
          echo "âŒ Lambda Tests: FAILED"
        fi
        
        if [ "${{ needs.build-test.result }}" = "success" ]; then
          echo "âœ… Build Test: PASSED"
        else
          echo "âŒ Build Test: FAILED"
        fi
        
        if [ "${{ needs.docs-check.result }}" = "success" ]; then
          echo "âœ… Documentation: PASSED"
        else
          echo "âŒ Documentation: FAILED"
        fi
        
        echo ""
        
        # Overall status
        if [ "${{ needs.code-quality.result }}" = "success" ] && \
           [ "${{ needs.unit-tests.result }}" = "success" ] && \
           [ "${{ needs.lambda-tests.result }}" = "success" ] && \
           [ "${{ needs.build-test.result }}" = "success" ] && \
           [ "${{ needs.docs-check.result }}" = "success" ]; then
          echo "ğŸ‰ All checks passed! This PR is ready for review."
        else
          echo "ğŸš¨ Some checks failed. Please review and fix the issues."
          exit 1
        fi
